---------- Original Page Content Start -----------

### Controlling and Limiting Traffic

Tyk supports controlling and limiting traffic for throttling and spike arrest use cases. Spike arrest sets a limit on the number of requests that can be processed within a specified time interval. If the incoming request rate exceeds this limit, then excess requests are throttled to ensure availability of the API server. 

From v2.8, when hitting quota or rate limits, the Gateway can automatically queue and auto-retry client requests. 

Throttling can be configured at a *key* or *policy* level via the following two fields: 

1. `throttle_interval`: Interval (in seconds) between each request retry.
2. `throttle_retry_limit`: Total request retry number.


### Set Request Throttling with the Dashboard

1.  At the key level: From **System Management** > **Keys** > **Add Key** or open an existing key.
    Or
    At the policy level: From **System Management** > **Policies** > **Add Policy** or open an existing policy.
    
2.  Ensure the new key or policy has access to the APIs you wish it work with by selecting the API from **Access Rights** > **Add Access Rule** and click **Add**.

3.  From the **Throttling** section, select the **Throttle interval** and the **Throttle retry limit** values.
    
{{< img src="/img/dashboard/system-management/throttling_update.png" alt="Tyk API Gateway Throttling" >}}

4.  Save the token/policy.

### Set Request Throttling in the object

Get the policy object with `GET /api/portal/policies/` or the key's session object via `GET /api/apis/{API-ID}/keys/` and then  set two fields, `throttle_interval` and `throttle_retry_limit` in the object and create a new object or update the exsiting one.

---------- Original Page Content END -----------


---------- Content Generate from Internal AI System Start -----------

Request Throttling Overview
---------------------------

Request Throttling in Tyk is a traffic control mechanism designed for spike arrest and throttling use cases. Unlike standard rate limiting that immediately rejects excess requests, throttling queues and automatically retries client requests when they hit quota or rate limits.

Configuration Options
---------------------

Request Throttling can be configured at both key and policy levels through the following parameters:

### 1.

`throttle_interval`

-   Description: The interval (in seconds) between each request retry
-   Type: Integer
-   Default: -1 (disabled)

### 2.

`throttle_retry_limit`

-   Description: The total number of retry attempts for a request
-   Type: Integer
-   Default: -1 (disabled)

Configuration Methods
---------------------

### Method 1: Using the Dashboard

1.  At the key level:

    -   Navigate to System Management > Keys > Add Key (or open an existing key)
    -   Ensure the key has access to the APIs you want it to work with
    -   In the Throttling section, set the Throttle interval and Throttle retry limit values
    -   Save the token
2.  At the policy level:

    -   Navigate to System Management > Policies > Add Policy (or open an existing policy)
    -   Ensure the policy has access to the APIs you want it to work with by selecting the API from Access Rights > Add Access Rule
    -   In the Throttling section, set the Throttle interval and Throttle retry limit values
    -   Save the policy

### Method 2: Directly in the Object

1.  Get the policy object with

    `GET /api/portal/policies/`

    or the key's session object via

    `GET /api/apis/{API-ID}/keys/`

2.  Set the

    `throttle_interval`

    and

    `throttle_retry_limit`

    fields in the object
3.  Create a new object or update the existing one

Disabling Request Throttling
----------------------------

Request Throttling is disabled by default. To explicitly disable it:

-   Set both

    `throttle_interval`

    and

    `throttle_retry_limit`

    values to less than 0
-   The default value is -1, which means the feature is disabled by default

How Request Throttling Works
----------------------------

When a client exceeds quota or rate limits:

1.  Instead of immediately returning a 429 error (Too Many Requests), Tyk will queue the request
2.  Tyk will retry the request after waiting for the specified

    `throttle_interval`

    seconds
3.  This process continues until either:
    -   The request succeeds (when capacity becomes available)
    -   The

        `throttle_retry_limit`

        is reached
    -   If the retry limit is reached, Tyk will finally return a 429 error to the client

Difference from Standard Rate Limiting
--------------------------------------

Request Throttling complements Tyk's standard rate limiting functionality:

-   Rate Limiting: Immediately rejects excess requests with a 429 error
-   Request Throttling: Queues excess requests and retries them automatically

This provides a smoother experience for clients during traffic spikes or when they approach their quota limits.

Use Cases
---------

Request Throttling is particularly useful for:

1.  Protecting backend services from traffic spikes
2.  Providing a better user experience during high-traffic periods
3.  Implementing a "spike arrest" pattern to smooth out traffic
4.  Ensuring critical API calls eventually get through even during congestion

---------- Content Generate from Internal AI System END -----------